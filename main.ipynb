{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api import openai_api_key\n",
    "from langchain_openai import OpenAIEmbeddings, OpenAI\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List\n",
    "import numpy as np\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "import os\n",
    "import ast\n",
    "import time\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import YouTubeSearchTool\n",
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "tool = YouTubeSearchTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_youtube_id(url: str) -> str:\n",
    "    \"\"\"Extract video ID from YouTube URL\"\"\"\n",
    "    try:\n",
    "        parsed_url = urlparse(url)\n",
    "        if parsed_url.hostname in ['www.youtube.com', 'youtube.com']:\n",
    "            return parse_qs(parsed_url.query)['v'][0]\n",
    "        elif parsed_url.hostname == 'youtu.be':\n",
    "            return parsed_url.path[1:]\n",
    "    except:\n",
    "        return None\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# urls_string = tool.run(\"lex friedman, 5\")\n",
    "# # A tool to make string into a list of urls\n",
    "# urls = ast.literal_eval(urls_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# A tool to get the title of a youtube video. It is much faster that \"yt_dpl\"\n",
    "def get_youtube_title(url):\n",
    "    try:\n",
    "        # Get the page content\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "        \n",
    "        # Parse with BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find title meta tag\n",
    "        title = soup.find('meta', property='og:title')\n",
    "        if title:\n",
    "            return title['content']\n",
    "            \n",
    "        # Alternative method: find title tag\n",
    "        title = soup.find('title')\n",
    "        if title:\n",
    "            # Clean up the title (remove \"- YouTube\" suffix)\n",
    "            return re.sub(r'\\s*-\\s*YouTube$', '', title.string)\n",
    "            \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting title from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "title = get_youtube_title(url=\"https://youtu.be/cY-0TRj-teI?si=mEpB7q-tXZtroHnr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_content(url: str) -> tuple:\n",
    "    \"\"\"Safely get video content and metadata\"\"\"\n",
    "    try:\n",
    "        loader = YoutubeLoader.from_youtube_url(\n",
    "            url,\n",
    "            add_video_info=False,\n",
    "            language=['en', 'ko']  # Support both English and Korean\n",
    "        )\n",
    "        \n",
    "        content = loader.load()\n",
    "        \n",
    "        if not content or len(content) == 0:\n",
    "            return None, None\n",
    "            \n",
    "        return content[0].page_content, content[0].metadata\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading content for {url}: {str(e)}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We construct a Dictionary of titles as a key of the dictionary and values as \"content\", \"metadata\" and \"url\"\n",
    "def get_dict(urls):\n",
    "    video_dict = {}\n",
    "    for url in urls:\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "        title = get_youtube_title(url)\n",
    "        content, metadata = get_video_content(url)\n",
    "\n",
    "        if content is None:\n",
    "            print(f\"Skipping {url} due to content loading error\")\n",
    "            continue\n",
    "\n",
    "        video_dict[title] = {\"content\": content,\n",
    "                        \"metadata\": metadata,\n",
    "                        \"url\": url}  \n",
    "    return video_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_similarity(title, content):\n",
    "    # Given title and the content, return the similarity of the title and content in percentage\n",
    "    llm = OpenAI(temperature=0)\n",
    "    openai_embed = OpenAIEmbeddings()\n",
    "\n",
    "    title_embed = openai_embed.embed_query(title)\n",
    "    \n",
    "    content_embed = openai_embed.embed_query(content)\n",
    "    similarity = cosine_similarity(title_embed, content_embed)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fact_checker(query, num_videos=5):\n",
    "    similarity_list = []\n",
    "    tool = YouTubeSearchTool()\n",
    "    string_urls = tool.run(f\"{query}, {num_videos}\")\n",
    "    urls = ast.literal_eval(string_urls) # Now we have the list of urls\n",
    "\n",
    "    video_dict = get_dict(urls)\n",
    "    similarity_key_dict = {}\n",
    "\n",
    "    for key in video_dict.keys():\n",
    "        title=key\n",
    "        content = video_dict[key][\"content\"]\n",
    "        url = video_dict[key][\"url\"]\n",
    "        similarity = check_similarity(title=title, content=content)\n",
    "        similarity = round(similarity*100, 2)\n",
    "        similarity_list.append(similarity)\n",
    "        video_dict[key][\"similarity\"] = str(similarity)\n",
    "\n",
    "        similarity_key_dict[str(similarity)] = {\"title\": title,\n",
    "                                                \"content\": content,\n",
    "                                                \"url\": url}\n",
    "\n",
    "    return video_dict, similarity_list, similarity_key_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_dict, similarity_list, similarity_key_dict = fact_checker(\"í•œêµ­ ëŒ€í†µë ¹ íƒ„í•µ \", num_videos=10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88.31, 86.31, 85.12, 83.15, 85.08, 89.37, 87.8, 87.36, 84.56, 87.02]\n"
     ]
    }
   ],
   "source": [
    "print(similarity_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89.37, 88.31, 87.8, 87.36, 87.02, 86.31, 85.12, 85.08, 84.56, 83.15]\n"
     ]
    }
   ],
   "source": [
    "new_list = sorted(similarity_list,reverse=True)\n",
    "print(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 89.37 | Title: [ì—ë””í„°í”½] ìœ¤ ëŒ€í†µë ¹ íƒ„í•µì•ˆ ê°€ê²°..ë¯¸êµ­ ì •ë¶€ê°€ ë°íŒ ê³µì‹ ì…ì¥ / YTN | url: https://www.youtube.com/watch?v=4TkqFjgeAho&pp=ygUY7ZWc6rWtIOuMgO2GteuguSDtg4TtlbUg\n",
      "Similarity: 88.31 | Title: [LIVE] 'ìœ¤ì„ì—´ ëŒ€í†µë ¹ íƒ„í•µì†Œì¶”ì•ˆ' ê°€ê²°...ê´‘í™”ë¬¸ ì¼ëŒ€ 'íƒ„í•µ ë°˜ëŒ€' ì§‘íšŒ í˜„ì¥ ìƒí™©/2024ë…„ 12ì›” 14ì¼(í† )/KBS | url: https://www.youtube.com/watch?v=vNj4lCzL4KQ&pp=ygUY7ZWc6rWtIOuMgO2GteuguSDtg4TtlbUg\n",
      "Similarity: 87.8 | Title: ë¯¸ ì–¸ë¡ , íƒ„í•µ ê°€ê²° ì¼ì œíˆ ì†ë³´ íƒ€ì „...ë¯¸ ì •ë¶€ë„ 'ì´‰ê°' / YTN | url: https://www.youtube.com/watch?v=FAxPAVmkOz0&pp=ygUY7ZWc6rWtIOuMgO2GteuguSDtg4TtlbUg\n",
      "Similarity: 87.36 | Title: 8ë…„ ì „ì²˜ëŸ¼â€¦íŠ¸ëŸ¼í”„ ì·¨ì„ ë•Œë§ˆë‹¤ 'í•œêµ­ ëŒ€í†µë ¹ì€ íƒ„í•µ ì¤‘' / JTBC News | url: https://www.youtube.com/watch?v=cR94yJG7dUw&pp=ygUY7ZWc6rWtIOuMgO2GteuguSDtg4TtlbUg\n",
      "Similarity: 87.02 | Title: ìœ¤ì„ì—´ ëŒ€í†µë ¹ 'ë‚´ë€' íƒ„í•µì•ˆ ê°€ê²°â€¥ì§ë¬´ì •ì§€ - [LIVE] MBC íŠ¹ì§‘ ë‰´ìŠ¤ë°ìŠ¤í¬ 2024ë…„ 12ì›” 14ì¼ | url: https://www.youtube.com/watch?v=tdr5t21hbj8&pp=ygUY7ZWc6rWtIOuMgO2GteuguSDtg4TtlbUg\n",
      "Similarity: 86.31 | Title: ì™¸ì‹ ë“¤, 'ìœ¤ íƒ„í•µ' ê¸´ê¸‰íƒ€ì „â€¦ì¤‘êµ­ í¬í„¸ ê²€ìƒ‰ì–´ 1ìœ„ì— (ìë§‰ë‰´ìŠ¤) / SBS | url: https://www.youtube.com/watch?v=L2SO--lHJu0&pp=ygUY7ZWc6rWtIOuMgO2GteuguSDtg4TtlbUg\n",
      "Similarity: 85.12 | Title: [ìë§‰ë‰´ìŠ¤] ì™¸ì‹ ì— 'ê·¼ì¡°í™”í™˜' ë“±ì¥...\"í•œêµ­ì‹ ì €í•­\" K-ì‹œìœ„ì— ë¹„ìƒí•œ ê´€ì‹¬ / YTN | url: https://www.youtube.com/watch?v=cwkpwVxabmQ&pp=ygUY7ZWc6rWtIOuMgO2GteuguSDtg4TtlbUg\n",
      "Similarity: 85.08 | Title: [ğŸ”´LIVE]  ìœ¤ ëŒ€í†µë ¹ íƒ„í•µì•ˆ 'ê°€ê²°'ã…£ë‰´ìŠ¤íŠ¹ë³´ / YTN | url: https://www.youtube.com/watch?v=sQSFtdLkSB8&pp=ygUY7ZWc6rWtIOuMgO2GteuguSDtg4TtlbUg\n",
      "Similarity: 84.56 | Title: ìœ¤ì„ì—´ ëŒ€í†µë ¹, â€˜íƒ„í•µì†Œì¶”ì•ˆ ê°€ê²°â€™ ê´€ë ¨ ì…ì¥ ë°œí‘œ - [ëê¹Œì§€LIVE] MBC ì¤‘ê³„ë°©ì†¡ 2024ë…„ 12ì›” 14ì¼ | url: https://www.youtube.com/watch?v=gLlN9BN_2X0&pp=ygUY7ZWc6rWtIOuMgO2GteuguSDtg4TtlbUg\n",
      "Similarity: 83.15 | Title: [ì—ë””í„°í”½] íƒ„í•µì•ˆ ê°€ê²°ì—â€¦'í„°ì¤ëŒ€ê°' í™ì¤€í‘œê°€ ë‚¨ê¸´ ë§ / YTN | url: https://www.youtube.com/watch?v=cDbU7e2ywLw&pp=ygUY7ZWc6rWtIOuMgO2GteuguSDtg4TtlbUg\n"
     ]
    }
   ],
   "source": [
    "for num in new_list:\n",
    "    title = similarity_key_dict[str(num)][\"title\"]\n",
    "    url = similarity_key_dict[str(num)][\"url\"]\n",
    "    print(f\"Similarity: {num} | Title: {title} | url: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
